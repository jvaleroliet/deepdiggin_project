{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vinyl Grading Project\n",
    "This project aims to construct an open source package to classify vinyl according to the [Goldmine Grading](https://www.goldminemag.com/collector-resources/record-grading-101).\n",
    "\n",
    "First we need to create a Dataset. We will scrap some pages in search of labeled audio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrapin WatchCount\n",
    "\n",
    "WatchCount is an archive of ebay sold items. I've selected one user that uses a template for the description and that includes always an audio. This will help us to create semi-automatically the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (19 kB)\n",
      "Collecting selenium\n",
      "  Downloading selenium-4.22.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting requests\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting numpy>=1.26.0 (from pandas)\n",
      "  Downloading numpy-2.0.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (114 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/vinyl_grade/lib/python3.12/site-packages (from pandas) (2.9.0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting urllib3<3,>=1.26 (from urllib3[socks]<3,>=1.26->selenium)\n",
      "  Downloading urllib3-2.2.2-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting trio~=0.17 (from selenium)\n",
      "  Downloading trio-0.26.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting trio-websocket~=0.9 (from selenium)\n",
      "  Downloading trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting certifi>=2021.10.8 (from selenium)\n",
      "  Downloading certifi-2024.7.4-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in /opt/anaconda3/envs/vinyl_grade/lib/python3.12/site-packages (from selenium) (4.12.2)\n",
      "Collecting websocket-client>=1.8.0 (from selenium)\n",
      "  Downloading websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests)\n",
      "  Downloading charset_normalizer-3.3.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (33 kB)\n",
      "Collecting idna<4,>=2.5 (from requests)\n",
      "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/vinyl_grade/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Collecting attrs>=23.2.0 (from trio~=0.17->selenium)\n",
      "  Downloading attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting sortedcontainers (from trio~=0.17->selenium)\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting outcome (from trio~=0.17->selenium)\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting sniffio>=1.3.0 (from trio~=0.17->selenium)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pysocks!=1.5.7,<2.0,>=1.5.6 (from urllib3[socks]<3,>=1.26->selenium)\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket~=0.9->selenium)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Downloading pandas-2.2.2-cp312-cp312-macosx_11_0_arm64.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading selenium-4.22.0-py3-none-any.whl (9.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading certifi-2024.7.4-py3-none-any.whl (162 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.0/163.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading charset_normalizer-3.3.2-cp312-cp312-macosx_11_0_arm64.whl (119 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.0.0-cp312-cp312-macosx_11_0_arm64.whl (13.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m505.5/505.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading trio-0.26.0-py3-none-any.whl (475 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.7/475.7 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
      "Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading urllib3-2.2.2-py3-none-any.whl (121 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.4/121.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sortedcontainers, pytz, websocket-client, urllib3, tzdata, sniffio, pysocks, numpy, idna, h11, charset-normalizer, certifi, attrs, wsproto, requests, pandas, outcome, trio, trio-websocket, selenium\n",
      "Successfully installed attrs-23.2.0 certifi-2024.7.4 charset-normalizer-3.3.2 h11-0.14.0 idna-3.7 numpy-2.0.0 outcome-1.3.0.post0 pandas-2.2.2 pysocks-1.7.1 pytz-2024.1 requests-2.32.3 selenium-4.22.0 sniffio-1.3.1 sortedcontainers-2.4.0 trio-0.26.0 trio-websocket-0.11.1 tzdata-2024.1 urllib3-2.2.2 websocket-client-1.8.0 wsproto-1.2.0\n"
     ]
    }
   ],
   "source": [
    "# install required packages if needed\n",
    "!pip install pandas selenium requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's open a session\n",
    "driver = webdriver.Firefox()\n",
    "url = \"http://www.watchcount.com/completed.php?bfw=1&bslr=wills-rare-records\"\n",
    "driver.get(url)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a dataframe for the url to the actual item on ebay and the title of the item sold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_links = pd.DataFrame(columns=[\"Link\",\"Title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Link</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Link, Title]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now is time to scrape all the table of sold items from this seller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the table's xpath\n",
    "table = driver.find_element(By.XPATH, \"/html/body/div/table/tbody/tr[3]/td/table/tbody/tr/td[2]/div/table[2]/tbody/tr[2]/td/div/table[1]\")\n",
    "\n",
    "# Find all rows within the table\n",
    "rows = table.find_elements(By.TAG_NAME, \"tr\")\n",
    "\n",
    "# Loop through each row\n",
    "for row in rows:\n",
    "    # Find all link elements within the row\n",
    "    links = row.find_elements(By.TAG_NAME, \"a\")\n",
    "    # Loop through each link element\n",
    "    if len(links)==11:\n",
    "\n",
    "    # Extract the URL from the href attribute\n",
    "        url = links[1].get_attribute(\"href\")\n",
    "        text = links[1].get_attribute(\"text\")\n",
    "        \n",
    "        df_links.loc[len(df_links)] = [url, text]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look on the dataframe of the first scraped page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Link</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.watchcount.com/go/?item=11623035299...</td>\n",
       "      <td>Ahmed al-Jaberi - Rare SUDAN Arabic Afro 45 / ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.watchcount.com/go/?item=11623035299...</td>\n",
       "      <td>Ahmed al-Jaberi - Rare SUDAN Arabic Afro 45 / ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.watchcount.com/go/?item=11623035039...</td>\n",
       "      <td>Mohamed Mirghani - Rare SUDAN Arabic Afro 45 /...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.watchcount.com/go/?item=11623034962...</td>\n",
       "      <td>Tayeb Abdullah ? - Rare SUDAN Arabic Afro 45 /...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.watchcount.com/go/?item=11623034725...</td>\n",
       "      <td>Ibrahim Awad - Ya Zaman - Rare SUDAN Arabic Af...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>http://www.watchcount.com/go/?item=11620727474...</td>\n",
       "      <td>Asnaketch Worku – Krar Songs - ETHIOPIA Rare F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>http://www.watchcount.com/go/?item=11620668755...</td>\n",
       "      <td>Tekle Tesfazghi ‎– Abadit - ERITREA (Ethiopia)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>http://www.watchcount.com/go/?item=11620727128...</td>\n",
       "      <td>Ashenafi Kebede &amp; The Hungarian State String O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>http://www.watchcount.com/go/?item=11620668101...</td>\n",
       "      <td>Black Magic Band - ZAMBIA Invisible Super Rare...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>http://www.watchcount.com/go/?item=11620726877...</td>\n",
       "      <td>Super Mazembe - Naleli Libota - KENYA Sweet Li...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Link  \\\n",
       "0    http://www.watchcount.com/go/?item=11623035299...   \n",
       "1    http://www.watchcount.com/go/?item=11623035299...   \n",
       "2    http://www.watchcount.com/go/?item=11623035039...   \n",
       "3    http://www.watchcount.com/go/?item=11623034962...   \n",
       "4    http://www.watchcount.com/go/?item=11623034725...   \n",
       "..                                                 ...   \n",
       "96   http://www.watchcount.com/go/?item=11620727474...   \n",
       "97   http://www.watchcount.com/go/?item=11620668755...   \n",
       "98   http://www.watchcount.com/go/?item=11620727128...   \n",
       "99   http://www.watchcount.com/go/?item=11620668101...   \n",
       "100  http://www.watchcount.com/go/?item=11620726877...   \n",
       "\n",
       "                                                 Title  \n",
       "0    Ahmed al-Jaberi - Rare SUDAN Arabic Afro 45 / ...  \n",
       "1    Ahmed al-Jaberi - Rare SUDAN Arabic Afro 45 / ...  \n",
       "2    Mohamed Mirghani - Rare SUDAN Arabic Afro 45 /...  \n",
       "3    Tayeb Abdullah ? - Rare SUDAN Arabic Afro 45 /...  \n",
       "4    Ibrahim Awad - Ya Zaman - Rare SUDAN Arabic Af...  \n",
       "..                                                 ...  \n",
       "96   Asnaketch Worku – Krar Songs - ETHIOPIA Rare F...  \n",
       "97   Tekle Tesfazghi ‎– Abadit - ERITREA (Ethiopia)...  \n",
       "98   Ashenafi Kebede & The Hungarian State String O...  \n",
       "99   Black Magic Band - ZAMBIA Invisible Super Rare...  \n",
       "100  Super Mazembe - Naleli Libota - KENYA Sweet Li...  \n",
       "\n",
       "[101 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look's good. Let's scrape the rest of 8 pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,9):\n",
    "    driver = webdriver.Firefox()\n",
    "    url = \"http://www.watchcount.com/completed.php?bslr=wills-rare-records&csbin=all&cssrt=ts&bfw=1&bpg={}#serp\".format(i)\n",
    "    driver.get(url)\n",
    "    table = driver.find_element(By.XPATH, \"/html/body/div/table/tbody/tr[3]/td/table/tbody/tr/td[2]/div/table[2]/tbody/tr[2]/td/div/table[1]\")\n",
    "\n",
    "    # Find all rows within the table\n",
    "    rows = table.find_elements(By.TAG_NAME, \"tr\")\n",
    "\n",
    "    # Loop through each row\n",
    "    print(i)\n",
    "    for row in rows:\n",
    "        try:\n",
    "            # Find all link elements within the row\n",
    "            links = row.find_elements(By.TAG_NAME, \"a\")\n",
    "            \n",
    "            # Loop through each link element\n",
    "            if len(links)==11:\n",
    "\n",
    "                # Extract the URL from the href attribute\n",
    "                url = links[1].get_attribute(\"href\")\n",
    "                text = links[1].get_attribute(\"text\")\n",
    "                df_links.loc[len(df_links)] = [url, text]\n",
    "        except:\n",
    "            print(row)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's store the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_links.to_csv(\"./output/wills.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vinyl_grade",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
